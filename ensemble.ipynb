{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dfd8ae6",
   "metadata": {},
   "source": [
    "# Ensemble learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c181c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b66ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples = 500, noise = 0.30, random_state = 42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af5a5369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n",
       "                             ('rf', RandomForestClassifier(random_state=42)),\n",
       "                             ('svc', SVC(random_state=42))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "    estimators = [('lr', LogisticRegression(random_state =42)),\n",
    "                 ('rf', RandomForestClassifier(random_state = 42)),\n",
    "                 ('svc', SVC(random_state=42))]\n",
    ")\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0abc1cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 0.864\n",
      "rf = 0.896\n",
      "svc = 0.896\n"
     ]
    }
   ],
   "source": [
    "for name, clf in voting_clf.named_estimators_.items():\n",
    "    print(name, \"=\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e2a4461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting classes (hard voting) - voting based on largest group of predictions\n",
    "\n",
    "voting_clf.predict(X_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d11a9e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1]), array([1]), array([0])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[clf.predict(X_test[:1]) for clf in voting_clf.estimators_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d9f1fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scoring\n",
    "voting_clf.score(X_test, y_test) #outperforms all individual classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd7a9059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#soft voting - voting based on avg probabilites \n",
    "voting_clf.voting = \"soft\"\n",
    "voting_clf.named_estimators[\"svc\"].probability = True\n",
    "voting_clf.fit(X_train, y_train)\n",
    "voting_clf.score(X_test, y_test) #higher than hard voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd00240",
   "metadata": {},
   "source": [
    "## Bagging (bootstrap aggregating) and pasting\n",
    "* training same algorithms on different subsets of data (with replacement) - bagging\n",
    "* training same algorithms on different subsets of data (w/o replacement) - pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03b2793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "427c2efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(), max_samples=100,\n",
       "                  n_estimators=500, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators = 500,\n",
    "                           max_samples = 100, n_jobs = -1, random_state = 42)\n",
    "bag_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bf111f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.904"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.score(X_test, y_test) #bagging has slightly higher bias than pasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a7f358",
   "metadata": {},
   "source": [
    "### out of bag evaluation\n",
    "Mathematically only about 63% of the training instances are sampled on an average for each predictor. The remaining 37% of the training instances that are not sampled are called out-of-bag(OOB) instances.\n",
    "\n",
    "A bagging ensemble can be evaluated using OOB instances, without the need for a separate validation se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee1663db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500, \n",
    "                           oob_score = True, n_jobs = -1, random_state=42)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf.oob_score_ #classifier is likely to achieve about 89.6% accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d04b6254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8e14e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, bag_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f9df330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.32352941, 0.67647059],\n",
       "       [0.3375    , 0.6625    ],\n",
       "       [1.        , 0.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OOB decision function (because underlying algo has predict_proba() method)\n",
    "bag_clf.oob_decision_function_[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beac6dea",
   "metadata": {},
   "source": [
    "## Random patches and Random subspaces\n",
    "\n",
    "just as we choose subset of instances for each estimator, we can choose features instead with `max_features` and `bootstrap_features` hyperparameters.\n",
    "\n",
    "Sampling both training instances and features is called the `random patches method`\n",
    "\n",
    "Keeping all training instances (by setting `bootstrap=False` and `max_samples=1.0`) but sampling features (by setting bootstrap_features to True and/or max_features to a value smaller than 1.0) is called the `random subspaces` method.‚Å†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8444dd14",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "\n",
    "* same as training an ensemble classifier with decision trees via bagging method <br>\n",
    "* at each node only a random subset of the 'best' features is considered for splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12b5e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2777b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators = 500, max_leaf_nodes = 16,\n",
    "                                n_jobs = -1, random_state = 42)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4713951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8133807",
   "metadata": {},
   "source": [
    "by default uses $\\sqrt{n}$ features out of n.<br>\n",
    "Trades higher bias for a lower variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb58332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(max_features = \"sqrt\", max_leaf_nodes = 16),\n",
    "                           n_estimators = 500, n_jobs = -1, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f5a974",
   "metadata": {},
   "source": [
    "### extremely random trees (extra-trees)\n",
    "* random forest with splitting nodes using random thresholds for each features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d4c87fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra trees; making trees even more random \n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f85736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_clf = ExtraTreesClassifier(random_state=42,)\n",
    "extra_clf.fit(X_train, y_train)\n",
    "y_pred_extra  = extra_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b01b5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_extra, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63574720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of RandomForestClassifier(max_leaf_nodes=16, n_estimators=500, n_jobs=-1,\n",
       "                       random_state=42)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier(bootstrap=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "341518a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_clf = BaggingClassifier(DecisionTreeClassifier(max_features = \"sqrt\", max_leaf_nodes = 16, splitter='random'),\n",
    "                           n_estimators = 500, n_jobs = -1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9cbd7860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_clf.fit(X_train, y_train)\n",
    "accuracy_score(y_test, ex_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023466de",
   "metadata": {},
   "source": [
    "### feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "115375c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, random_state=42)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris(as_frame = True)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, random_state = 42)\n",
    "rnd_clf.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a6f0615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) : 0.11\n",
      "sepal width (cm) : 0.02\n",
      "petal length (cm) : 0.44\n",
      "petal width (cm) : 0.42\n"
     ]
    }
   ],
   "source": [
    "for score,name in zip(rnd_clf.feature_importances_,iris.data.columns):\n",
    "    print(name, \":\", round(score,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3488df2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
