# learn-ML
Introduction to Machine learning (based on [CS229](https://cs229.stanford.edu/) from stanford university)<br>

<ul>
<li> <a href="https://cs229.stanford.edu/"> Course website </li>
<li><a href="https://www.youtube.com/playlist?list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU"> Video lectures </li>
<li><a href="https://see.stanford.edu/Course/CS229"> vintage version of cs229 </a>  </li>
</ul>

<table>
<tr>
<th> Concept </th>
<th> lecture </th>
<th> applications</th>
<th> extras </th>
</tr>
<tr>
<td> 
	<p> Linear models 
<ul>
	<li> <a href="ordinary_linear_reg_grad_descent.ipynb"> linear regression (gradient descent) </a> </li>
	<li>  <a href="ord_linear_reg_stochastic_GD.ipynb"> linear regression (stochastic GD) </a> </li>
	<li> <a href="Polynomial_regression.ipynb"> Polynomial regression </a> </li>
	<li> <a href="newton_raphson_log_reg.ipynb"> Logistic regression </a> </li>
	<li> <a href="multiclass_classification_softmax.ipynb"> Softmax regression(multiclass) </a> </li>
	<li> <a href="plot_poisson_regression_non_normal_loss.ipynb"> Poisson regression </a> </li>
	<li> <a href="plot_tweedie_regression_insurance_claims.ipynb"> GLM </a>	</li>
    </ul></p>
</td>
<td>
<ul>
<li> <a href="https://www.youtube.com/watch?v=4b4MUYve_U8&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&index=2"> ML problem setup </a> </li>
<li> <a href="https://www.youtube.com/watch?v=4b4MUYve_U8&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&index=2"> LR and GD </a> </li>
<li> <a href="https://www.youtube.com/watch?v=het9HFqo1TQ&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&index=3"> Weighted & Logistic regression </a> </li>
<li> <a href="https://www.youtube.com/watch?v=iZTeva0WSTQ&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&index=4"> GLMs & cross-entroy min </a> </li>

</ul>
 </td>
<td> <ul>
	<li> <a href="pred_diabetes_progress.ipynb"> Predicting diabetes progression</a> </li>
	</ul>
</td>
<td>
<ul>
<li> <a href="https://towardsdatascience.com/assumptions-of-linear-regression-fdb71ebeaa8b"> assumptions of LR </a> </li>
<li> <a href="https://dl.acm.org/doi/10.1162/neco.1996.8.7.1341"> No free lunch </a> </li> 
<li> <a href="https://static.googleusercontent.com/media/research.google.com/fr//pubs/archive/35179.pdf"> data effects </a> </li>
<li> <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3164764"> case study: GLM </a> </li>
 </ul>
 </td>
</tr>
<tr> 
<td>	<ul>
<li> <a href="Naive_bayes.ipynb"> Naive Bayes </a> </li>
</ul>
</td>
<td>
<ul>
<li> <a href="https://www.youtube.com/watch?v=nt63k3bfXS0&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&index=5"> GDA and Naive Bayes </a> </li>
</ul>
<td>
</td>
<td>
</td>
</tr>
<tr> 
 <td>
   <ul>
 <li> <a href="SVM_classifiers.ipynb">Support Vector Machines </a></li>
   </ul>
 </td>
 <td>
  <ul>
   <li> <a href="https://www.youtube.com/watch?v=lDwow4aOrtg&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&index=6"> Support Vector Machines </a> </li>
   <li> <a href="https://www.youtube.com/watch?v=8NYoQiRANpg&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&index=7"> Kernels </a> </li>
</ul>
</td>
<td> <ul> <li> <a href="MNIST_svm.ipynb"> Digit recognition </a> </li> </ul>
</td>
<td> </td>
</tr>
</table>


